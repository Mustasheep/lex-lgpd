{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "715f8944",
   "metadata": {},
   "source": [
    "### 1. Extração dos dados\n",
    "\n",
    "_07 de jul 2025_\n",
    "\n",
    "O texto com os artigos da lei LGPD serão extraídos do site Planalto, em uma versão compilada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e08f531",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea223332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estabelecendo variáveis universais e header\n",
    "URL = \"https://www.planalto.gov.br/ccivil_03/_ato2015-2018/2018/lei/L13709compilado.htm\"\n",
    "RAW_DATA_PATH = os.path.join (\"..\", \"data\", \"raw\", \"lgpd_raw.txt\")\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36 Edg/138.0.0.0',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79c415b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acesso bem sucedido!\n"
     ]
    }
   ],
   "source": [
    "# Tentando obter resposta da URL\n",
    "try:\n",
    "    response = requests.get(URL, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    print(\"Acesso bem sucedido!\")\n",
    "except Exception as e:\n",
    "    print(f\"Falha ao acessar a URL, erro: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f240848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estabelecendo o parser para html\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Encoding utilizado pelo site\n",
    "response.encoding = 'windows-1252'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "216f0ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extração bem sucedida\n"
     ]
    }
   ],
   "source": [
    "# Extraindo o texto alvo\n",
    "lista_de_artigos = \"\"\n",
    "try:\n",
    "    lista_de_artigos = soup.select('p.Artigo, p.MsoNormal')\n",
    "    \n",
    "    if type(lista_de_artigos) != type(None):\n",
    "        print(f\"Extração bem sucedida\")\n",
    "    else:\n",
    "        print(\"O texto não foi extraído e o resultado foi 'Nulo'\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Erro na extração: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40d1f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artigos encontrados. Preparando uma lista...\n",
      "\n",
      "Lista de artigos criada com sucesso: 396 artigos foram listados\n"
     ]
    }
   ],
   "source": [
    "# Por ser uma página mais antiga, é necessário alguns usos específicos de HTML\n",
    "texto_bruto = []\n",
    "if lista_de_artigos:\n",
    "    print(f\"Artigos encontrados. Preparando uma lista...\\n\")\n",
    "    \n",
    "    for i, artigo_tag in enumerate(lista_de_artigos):\n",
    "        texto_do_artigo = artigo_tag.get_text(strip=True)\n",
    "        texto_bruto.append(texto_do_artigo)\n",
    "    print(f\"Lista de artigos criada com sucesso: {len(lista_de_artigos)} artigos foram listados\")\n",
    "else:\n",
    "    print(\"Nenhum parágrafo com a classe 'Artigo' foi encontrado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf37fb92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['§ 4ş No cálculo do valor da multa de que trata o inciso II docaputdeste artigo, a autoridade nacional poderá considerar o faturamento total da empresa ou grupo de empresas, quando năo dispuser do valor do faturamento no ramo de atividade empresarial em que ocorreu a infraçăo, definido pela autoridade nacional, ou quando o valor for apresentado de forma incompleta ou năo for demonstrado de forma inequívoca e idônea.',\n",
       " 'Art. 53. A autoridade nacional definirá, por meio de regulamento próprio sobre sançőes administrativas a infraçőes a esta Lei, que deverá ser objeto de consulta pública, as metodologias que orientarăo o cálculo do valor-base das sançőes de multa.(Vigęncia)',\n",
       " '§ 1ş As metodologias a que se refere ocaputdeste artigo devem ser previamente publicadas, para cięncia dos agentes de tratamento, e devem apresentar objetivamente as formas e dosimetrias para o cálculo do valor-base das sançőes de multa, que deverăo conter fundamentaçăo detalhada de todos os seus elementos, demonstrando a observância dos critérios previstos nesta Lei.',\n",
       " '§ 2ş O regulamento de sançőes e metodologias correspondentes deve estabelecer as circunstâncias e as condiçőes para a adoçăo de multa simples ou diária.',\n",
       " 'Art. 54. O valor da sançăo de multa diária aplicável ŕs infraçőes a esta Lei deve observar a gravidade da falta e a extensăo do dano ou prejuízo causado e ser fundamentado pela autoridade nacional.(Vigęncia)',\n",
       " 'Parágrafo único. A intimaçăo da sançăo de multa diária deverá conter, no mínimo, a descriçăo da obrigaçăo imposta, o prazo razoável e estipulado pelo órgăo para o seu cumprimento e o valor da multa diária a ser aplicada pelo seu descumprimento.',\n",
       " 'CAPÍTULO IXDA AUTORIDADE NACIONAL DE PROTEÇĂO DE DADOS (ANPD) E DO CONSELHO NACIONAL DE PROTEÇĂO DE DADOS PESSOAIS E DA PRIVACIDADE',\n",
       " 'Seçăo IDa Autoridade Nacional de Proteçăo de Dados (ANPD)',\n",
       " 'Art. 55. (VETADO).',\n",
       " 'Art. 55-B.(Revogado pela Lei nş 14.460, de 2022)',\n",
       " 'Art. 56. (VETADO).',\n",
       " 'Art. 57.(VETADO).',\n",
       " 'Seçăo IIDo Conselho Nacional de Proteçăo de Dados Pessoais e da Privacidade',\n",
       " 'Art. 58. (VETADO).',\n",
       " 'Art. 59. (VETADO).',\n",
       " 'CAPÍTULO XDISPOSIÇŐES FINAIS E TRANSITÓRIAS',\n",
       " 'Art. 60. ALei nş 12.965, de 23 de abril de 2014 (Marco Civil da Internet), passa a vigorar com as seguintes alteraçőes:',\n",
       " '“Art. 7ş ..................................................................',\n",
       " '.......................................................................................',\n",
       " 'X - exclusăo definitiva dos dados pessoais que tiver fornecido a determinada aplicaçăo de internet, a seu requerimento, ao término da relaçăo entre as partes, ressalvadas as hipóteses de guarda obrigatória de registros previstas nesta Lei e na que dispőe sobre a proteçăo de dados pessoais;']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto_bruto[350:370]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3075e13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertendo lista para string para salvar com write\n",
    "lgpd_raw = ' '.join(texto_bruto)\n",
    "\n",
    "with open(RAW_DATA_PATH, 'w', encoding='utf-8') as f:\n",
    "    f.write(lgpd_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23f0a12",
   "metadata": {},
   "source": [
    "Essa primeira etapa está concluída. A reestruturação do código será feita para criar um script de extração do texto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2f7868",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. Processamento dos Textos\n",
    "_08 de jul 2025_\n",
    " \n",
    "Transformar o arquivo lgpd_raw.txt (único bloco de texto longo e com ruídos) em uma lista de \"fragmentos de conhecimento\" (chunks) limpos, estruturados e significativos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e9569ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa2e77e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o modelo de português do Spacy (tamanho \"large\")\n",
    "nlp = spacy.load(\"pt_core_news_lg\", disable=[\"parser\", \"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "320957fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregnado arquivo\n",
    "with open(RAW_DATA_PATH, 'r', encoding='utf-8') as f:\n",
    "    raw_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81808a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto bruto limpo\n"
     ]
    }
   ],
   "source": [
    "# Removendo as quebras de linhas múltiplas\n",
    "texto_processado = re.sub(r'\\n+', '\\n', raw_text).strip()\n",
    "\n",
    "# Otimizando o uso de espaços\n",
    "texto_processado = re.sub(r' +', ' ', texto_processado)\n",
    "print(\"Texto bruto limpo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6a8892",
   "metadata": {},
   "source": [
    "**Estratégia 1:** Quebrar o texto a cada 500 caracteres.\n",
    "\n",
    "* Problema: Isso pode cortar uma frase no meio, destruindo o sentido.\n",
    "\n",
    "**Estratégia 2:** Quebrar o texto por sentenças, usando o SpaCy.\n",
    "\n",
    "* Problema: Para um texto jurídico, uma única sentença pode ser curta demais e não ter o contexto completo de um artigo.\n",
    "\n",
    "**Estratégia 3:** Chunking Estrutural.\n",
    "\n",
    "- Lógica: O próprio documento já nos dá a melhor estrutura: os Artigos (Art. 1º, Art. 2º, etc.) e Capítulos. Cada artigo é uma unidade de pensamento completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50479122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CHUNKING ESTRUTURAL ---\n",
    "# Estabelecer um padrão do inicio de cada artigo com . ou ° e capitulos com numero romano (estrutura da lei)\n",
    "pattern = r'(Art\\.\\s\\d+°?\\.?|CAPÍTULO\\s[IVXLCDM]+)'\n",
    "\n",
    "# Dividir o texto com o pattern\n",
    "parts = re.split(pattern, texto_processado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc4b895",
   "metadata": {},
   "source": [
    "Cada chunk é o delimitador como \"Art. 1°\" ou \"Art. 23\" mais o texto que o segue. Iremos alternar entre o texto e o delimitador e reagrupar. A estrutura será gravada em JSON como dicionário durante a execução do script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "201323aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto dividido em 76 chunks estruturados.\n"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "for i in range(1, len(parts), 2):\n",
    "    chunk_title = parts[i].strip()\n",
    "    chunk_text = (parts[i] + parts[i+1]).strip()\n",
    "\n",
    "    chunks.append({\n",
    "        'id': len(chunks),\n",
    "        'source': chunk_title,\n",
    "        'text': chunk_text\n",
    "    })\n",
    "\n",
    "print(f\"Texto dividido em {len(chunks)} chunks estruturados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16f6cf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uma pequena amostra dos chunks:\n",
      "\n",
      "{'id': 0, 'source': 'Art. 1', 'text': 'Art. 1ş Esta Lei dispőe sobre o tratamento de dados pessoais, inclusive nos meios digitais, por pessoa natural ou por pessoa jurídica de direito público ou privado, com o objetivo de proteger os direitos fundamentais de liberdade e de privacidade e o livre desenvolvimento da personalidade da pessoa natural. Parágrafo único. As normas gerais contidas nesta Lei săo de interesse \\n\\tnacional e devem ser observadas pela Uniăo, Estados, Distrito Federal e \\n\\tMunicípios.(Incluído pela Lei \\n\\tnş 13.853, de 2019)Vigęncia'}\n",
      "{'id': 24, 'source': 'CAPÍTULO IVD', 'text': 'CAPÍTULO IVDO TRATAMENTO DE DADOS PESSOAIS PELO PODER PÚBLICO Seçăo IDas Regras'}\n",
      "{'id': 41, 'source': 'Art. 37.', 'text': 'Art. 37. O controlador e o operador devem manter registro das operaçőes de tratamento de dados pessoais que realizarem, especialmente quando baseado no legítimo interesse.'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Uma pequena amostra dos chunks:\\n\\n{chunks[0]}\\n{chunks[24]}\\n{chunks[41]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a7345f",
   "metadata": {},
   "source": [
    "A segunda etapa está concluída. A reestruturação do código será feita para criar um novo script de processamento do texto bruto e criação dos chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d892c1b9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Embeddings e Indexação - O Cérebro\n",
    "_10 de jul 2025_\n",
    "\n",
    "Converter os chunks de texto em vetores numéricos de alta dimensão e armazená-los em um banco de dados vetorial de alta velocidade (FAISS), ou seja, teremos o \"cérebro\" do assistente: uma representação matemática da LGPD que pode ser pesquisada por significado, não apenas por palavras-chave.\n",
    "\n",
    "**O que são Embeddings de Texto?**\n",
    "\n",
    "➥ Tecnicamente, é um vetor (uma lista) de números (ex: 384 ou 768 números) que captura a essência semântica de um texto.\n",
    "\n",
    "**O que é um Banco de Dados Vetorial?**\n",
    "\n",
    "➥ Um banco de dados vetorial é como um \"bibliotecário\" para vetores. Ele organiza os vetores de forma inteligente para encontrar outros vetores similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64ccc742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Thiag\\OneDrive\\Documentos\\Projetos Python\\lex-lgpd\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62df012b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo de embeddings\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# alterado no script para o uso do modelo 'rufimelo/bert-large-portuguese-cased-sts' , mais vantajoso e especializado para o português"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1294f520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de chunks de texto para processar: 76\n"
     ]
    }
   ],
   "source": [
    "# Extrai os textos para criação dos embeddings\n",
    "texts = [chunk['text'] for chunk in chunks]\n",
    "print(f\"Quantidade de chunks de texto para processar: {len(texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "667ff91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [00:05<00:00,  1.98s/it]\n"
     ]
    }
   ],
   "source": [
    "embeddings = model.encode(texts, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "14892201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings gerados. Formato do vetor: (76, 384)\n"
     ]
    }
   ],
   "source": [
    "# O FAISS aceita apenas o formato float32, necessário uma conversão\n",
    "embeddings = np.array(embeddings).astype('float32')\n",
    "\n",
    "print(f\"Embeddings gerados. Formato do vetor: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f1fc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Índice FAISS criado. Total de vetores no índice: 76\n"
     ]
    }
   ],
   "source": [
    "# Dimensão\n",
    "d = embeddings.shape[1] \n",
    "\n",
    "# Indice\n",
    "index = faiss.IndexFlatL2(d)\n",
    "\n",
    "# Atribuindo o índice aos embeddings\n",
    "index.add(embeddings)\n",
    "\n",
    "print(f\"Índice FAISS criado. Total de vetores no índice: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68954871",
   "metadata": {},
   "source": [
    "Terceira etapa está concluída. Os chunks foram transformados em vetores numéricos com embeddings e indexados com o FAISS. Novo script será construído."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515ee588",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. Mecanismos de Recuperação - O Sistema Nervoso\n",
    "_13 de jul 2025_\n",
    "\n",
    "Com o índice FAISS, armazenamos o conhecimento da LGPD em formato numérico e usaremos o arquivo Json como um mapa da sua memória. Com isso, o próximo passo é recuperar essas informações de forma acessível através de perguntas externas.\n",
    "\n",
    "Para isso, precisameros de um `input` com uma pergunta. Essa pergunta será transformada em um vetor numérico e usaremos a similaridade desses vetores para encontrar o melhor índice FAISS puxando as informações relevantes e gerar um `output` preciso e eficiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b540944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Atribuindo variáves importantes\n",
    "base_path = os.path.join(\"..\", \"data\", \"processed\")\n",
    "index_path = os.path.join(base_path, \"lgpd_faiss.index\")\n",
    "data_path = os.path.join(base_path, \"lgpd_chunks.json\")\n",
    "model_name = 'rufimelo/bert-large-portuguese-cased-sts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74aadc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-13 11:04:28,938 - INFO - Use pytorch device_name: cpu\n",
      "2025-07-13 11:04:28,939 - INFO - Load pretrained SentenceTransformer: rufimelo/bert-large-portuguese-cased-sts\n",
      "Invalid model-index. Not loading eval results into CardData.\n",
      "2025-07-13 11:04:31,583 - WARNING - Invalid model-index. Not loading eval results into CardData.\n"
     ]
    }
   ],
   "source": [
    "# Carregando arquivos e modelo\n",
    "index_f = faiss.read_index(index_path)\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    chunks_j = json.load(f)\n",
    "\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8845ae77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  5.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# Inserindo a pergunta e transformando em vetores\n",
    "query = \"O que são dados pessoais sensíveis?\"\n",
    "k_results = 3\n",
    "\n",
    "query_embedding = model.encode([query])\n",
    "query_embedding = np.array(query_embedding).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "950d6860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Depuração de Dimensões ---\n",
      "Shape do query_embedding: (1, 1024)\n",
      "Dimensão esperada pelo índice FAISS (index_f.d): 1024\n",
      "Número de dimensões do embedding da query (query_embedding.shape[1]): 1024\n",
      "As dimensões são iguais? True\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n--- Depuração de Dimensões ---\")\n",
    "print(f\"Shape do query_embedding: {query_embedding.shape}\")\n",
    "print(f\"Dimensão esperada pelo índice FAISS (index_f.d): {index_f.d}\")\n",
    "print(f\"Número de dimensões do embedding da query (query_embedding.shape[1]): {query_embedding.shape[1]}\")\n",
    "print(f\"As dimensões são iguais? {query_embedding.shape[1] == index_f.d}\")\n",
    "print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b19f674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar busca\n",
    "distance, indices = index_f.search(query_embedding, k_results)\n",
    "\n",
    "results = [chunks_j[i] for i in indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "90125980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultado da Busca ---\n",
      "Query: O que são dados pessoais sensíveis?\n",
      "\n",
      "Resultado 1 (ID: 18, Fonte: Art. 17.): \n",
      "Art. 17. Toda pessoa natural tem assegurada a titularidade de seus dados pessoais e garantidos os direitos fundamentais de liberdade, de intimidade e de privacidade, nos termos desta Lei.\n",
      "--------------------\n",
      "Resultado 2 (ID: 6, Fonte: CAPÍTULO IID): \n",
      "CAPÍTULO IIDO TRATAMENTO DE DADOS PESSOAIS Seçăo IDos Requisitos para o Tratamento de Dados Pessoais\n",
      "--------------------\n",
      "Resultado 3 (ID: 41, Fonte: Art. 37.): \n",
      "Art. 37. O controlador e o operador devem manter registro das operaçőes de tratamento de dados pessoais que realizarem, especialmente quando baseado no legítimo interesse.\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Resultado da Busca ---\")\n",
    "print(f\"Query: {query}\\n\")\n",
    "\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Resultado {i+1} (ID: {result['id']}, Fonte: {result['source']}): \")\n",
    "    print(result['text'])\n",
    "    print(\"-\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5620942b",
   "metadata": {},
   "source": [
    "A ideia de consulta está fluindo bem, mas o probela com os chunks precisa ser estudado e reestruturado. As mudanças irão ocorrer apenas no script que construií, permanecendo os registros do experimento transparentes durante o projeto. A partir disso, irei reestruturar as linhas de código e criar uma Classe com novas funções para a orquestração de toda essa quarta etapa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
